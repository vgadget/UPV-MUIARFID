{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/adrianvazquezbarrera/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords as sw\n",
    "from itertools import chain\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplified_lesk(context_sentence, ambiguous_word):\n",
    "    \n",
    "    stopwords = sw.words('english')\n",
    "    max_overlaps = -1; \n",
    "    lesk_sense = None\n",
    "    \n",
    "    context_sentence = [x for x in context_sentence.split() if x not in stopwords]\n",
    "        \n",
    "    for ss in wn.synsets(ambiguous_word):\n",
    "            \n",
    "        lesk_dictionary = []\n",
    "\n",
    "        # Includes definition.\n",
    "        lesk_dictionary += [x for x in ss.definition().split() if x not in stopwords]\n",
    "        \n",
    "        # Includes lemma_names.\n",
    "        lesk_dictionary += [x for x in ss.lemma_names() if x not in stopwords]\n",
    "        \n",
    "        lesk_dictionary = [re.sub(r'\\[.*?\\]|\\(.*?\\)|\\W+', ' ', x).replace('_', ' ') for x in lesk_dictionary]\n",
    "        \n",
    "        overlaps = set(lesk_dictionary).intersection(set(context_sentence))\n",
    "                        \n",
    "        if len(overlaps) > max_overlaps:\n",
    "            lesk_sense = ss\n",
    "            max_overlaps = len(overlaps)\n",
    "                \n",
    "    return lesk_sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase: Yesterday I went to the bank to withdraw the money and the credit card did not work \n",
      "Palabra: bank\n",
      "Desambiguación:\n",
      "a financial institution that accepts deposits and channels the money into lending activities\n",
      "------------------------------\n",
      "Frase: The river overflowed the bank. \n",
      "Palabra: bank\n",
      "Desambiguación:\n",
      "sloping land (especially the slope beside a body of water)\n",
      "------------------------------\n",
      "Frase: The van pulled up outside the bank and three masked men got out. \n",
      "Palabra: bank\n",
      "Desambiguación:\n",
      "a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
      "------------------------------\n",
      "Frase: The boy leapt from the bank into the cold water. \n",
      "Palabra: bank\n",
      "Desambiguación:\n",
      "sloping land (especially the slope beside a body of water)\n",
      "------------------------------\n",
      "Frase: I went fishing for some sea bass. \n",
      "Palabra: bass\n",
      "Desambiguación:\n",
      "the lowest part of the musical range\n",
      "------------------------------\n",
      "Frase: The bass line of the song is too weak. \n",
      "Palabra: bass\n",
      "Desambiguación:\n",
      "the lowest part of the musical range\n",
      "------------------------------\n",
      "Frase: I can hear bass frequency sound. \n",
      "Palabra: bass\n",
      "Desambiguación:\n",
      "the lowest part of the musical range\n",
      "------------------------------\n",
      "Frase: He likes to eat grilled bass fish. \n",
      "Palabra: bass\n",
      "Desambiguación:\n",
      "the lowest part of the musical range\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "frases=[(\"Yesterday I went to the bank to withdraw the money and the credit card did not work\",'bank'),\n",
    "       (\"The river overflowed the bank.\",'bank'),\n",
    "       (\"The van pulled up outside the bank and three masked men got out.\",'bank'),\n",
    "       (\"The boy leapt from the bank into the cold water.\",'bank'),\n",
    "       (\"I went fishing for some sea bass.\",'bass'),\n",
    "       (\"The bass line of the song is too weak.\",'bass'),\n",
    "       (\"I can hear bass frequency sound.\",'bass'),\n",
    "       (\"He likes to eat grilled bass fish.\",'bass')]\n",
    "\n",
    "for frase, palabra in frases:\n",
    "    print(f\"Frase: {frase} \\nPalabra: {palabra}\")\n",
    "    print(f\"Desambiguación:\")\n",
    "    print(simplified_lesk(frase, palabra).definition())\n",
    "    print(10*\"---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package word2vec_sample to\n",
      "[nltk_data]     /Users/adrianvazquezbarrera/nltk_data...\n",
      "[nltk_data]   Package word2vec_sample is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "from nltk.data import find\n",
    "import math\n",
    "import re\n",
    "\n",
    "nltk.download('word2vec_sample') \n",
    "\n",
    "\n",
    "# Cargar el modelo de embeding pre-entrenados del NLTK\n",
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(A, B):\n",
    "    \n",
    "    numerator = 0\n",
    "    denominatorA = 0\n",
    "    denominatorB = 0\n",
    "    \n",
    "    if (len(A) != len(B)):\n",
    "        raise Exception(\"Dimension does not match\")\n",
    "    \n",
    "    for i in range(len(A)):\n",
    "        numerator += A[i] * B[i]\n",
    "        denominatorA += A[i]**2\n",
    "        denominatorB += B[i]**2\n",
    "    \n",
    "    return numerator / (math.sqrt(denominatorA)) * (math.sqrt(denominatorB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(wn_word):\n",
    "    return (wn_word.name().split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_words(word, related_words, depth = 20, alpha = 0.5):\n",
    "    \n",
    "    words = []\n",
    "    rel = []\n",
    "    \n",
    "    for w in related_words:\n",
    "        try:\n",
    "            model[w]\n",
    "            rel.append(w)\n",
    "        except:\n",
    "            continue\n",
    "                           \n",
    "    for w, d in model.most_similar(positive=rel, topn=depth):\n",
    "        try:\n",
    "            if cosine_similarity( model[word], model[w] ) >= alpha:\n",
    "                #print(cosine_similarity( model[word], model[w] ))\n",
    "                words.append(w)\n",
    "        except:\n",
    "            continue\n",
    "         \n",
    "    return words\n",
    "\n",
    "\n",
    "def get_antonyms_words(word, related_words, depth=20, alpha = 0.5):\n",
    "    \n",
    "    words = []\n",
    "    rel = []\n",
    "    \n",
    "    for w in related_words:\n",
    "        try:\n",
    "            model[w]\n",
    "            rel.append(w)\n",
    "        except:\n",
    "            continue\n",
    "                \n",
    "    related_words = rel\n",
    "            \n",
    "    for w, d in model.most_similar(negative=related_words, topn = depth):\n",
    "        \n",
    "        if cosine_similarity( model[word], model[w]) <= alpha:\n",
    "            #print(cosine_similarity( model[word], model[w] ))\n",
    "            words.append(w)\n",
    "            \n",
    "    return words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings_lesk(context_sentence, ambiguous_word, depth = 40, alpha = 0.5):\n",
    "    \n",
    "    stopwords = sw.words('english')\n",
    "    max_overlaps = -1; \n",
    "    lesk_sense = None\n",
    "    \n",
    "    context_sentence = [x for x in context_sentence.split() if x not in stopwords]\n",
    "    \n",
    "    for ss in wn.synsets(ambiguous_word):\n",
    "            \n",
    "        lesk_dictionary = []\n",
    "\n",
    "        # Includes definition.\n",
    "        lesk_dictionary += [x for x in ss.definition().split() if x not in stopwords]\n",
    "        \n",
    "        # Includes lemma_names.\n",
    "        lesk_dictionary += [x for x in ss.lemma_names() if x not in stopwords]\n",
    "        \n",
    "        lesk_dictionary = [re.sub(r'\\[.*?\\]|\\(.*?\\)|\\W+', ' ', x).replace('_', ' ') for x in lesk_dictionary]\n",
    "        \n",
    "        l = []\n",
    "        for m in lesk_dictionary:\n",
    "            if \" \" in m:\n",
    "                l += m.split(\" \")\n",
    "            else:\n",
    "                l.append(m)\n",
    "                                    \n",
    "        lesk_dictionary = l\n",
    "        \n",
    "        lesk_dictionary += get_similar_words(get_name(ss), l, depth=depth, alpha=alpha)\n",
    "        lesk_dictionary = [re.sub(r'\\[.*?\\]|\\(.*?\\)|\\W+', ' ', x).replace('_', ' ') for x in lesk_dictionary]\n",
    "\n",
    "        overlaps = set(lesk_dictionary).intersection(context_sentence)\n",
    "        \n",
    "        \n",
    "        if len(overlaps) > max_overlaps:\n",
    "            lesk_sense = ss\n",
    "            max_overlaps = len(overlaps)\n",
    "                \n",
    "    return lesk_sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase: Yesterday I went to the bank to withdraw the money and the credit card did not work \n",
      "Palabra: bank\n",
      "Desambiguación:\n",
      "a financial institution that accepts deposits and channels the money into lending activities\n",
      "------------------------------\n",
      "Frase: The river overflowed the bank. \n",
      "Palabra: bank\n",
      "Desambiguación:\n",
      "sloping land (especially the slope beside a body of water)\n",
      "------------------------------\n",
      "Frase: The van pulled up outside the bank and three masked men got out. \n",
      "Palabra: bank\n",
      "Desambiguación:\n",
      "a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
      "------------------------------\n",
      "Frase: The boy leapt from the bank into the cold water. \n",
      "Palabra: bank\n",
      "Desambiguación:\n",
      "sloping land (especially the slope beside a body of water)\n",
      "------------------------------\n",
      "Frase: I went fishing for some sea bass. \n",
      "Palabra: bass\n",
      "Desambiguación:\n",
      "the lean flesh of a saltwater fish of the family Serranidae\n",
      "------------------------------\n",
      "Frase: The bass line of the song is too weak. \n",
      "Palabra: bass\n",
      "Desambiguación:\n",
      "the lowest part of the musical range\n",
      "------------------------------\n",
      "Frase: I can hear bass frequency sound. \n",
      "Palabra: bass\n",
      "Desambiguación:\n",
      "the lowest part of the musical range\n",
      "------------------------------\n",
      "Frase: He likes to eat grilled bass fish. \n",
      "Palabra: bass\n",
      "Desambiguación:\n",
      "the lowest part of the musical range\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for frase, palabra in frases:\n",
    "    print(f\"Frase: {frase} \\nPalabra: {palabra}\")\n",
    "    print(f\"Desambiguación:\")\n",
    "    print(embeddings_lesk(frase, palabra, depth=30, alpha=0.6).definition())\n",
    "\n",
    "    print(10*\"---\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
